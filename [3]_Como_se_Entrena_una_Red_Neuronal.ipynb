{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jurados/NotesPytorch/blob/main/%5B3%5D_Como_se_Entrena_una_Red_Neuronal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pExV9tXpDb2_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6LAsU_j-wOY"
      },
      "source": [
        "# Cómo se Entrena una Red Neuronal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmafUkGEJnQL"
      },
      "source": [
        "Aprender significa encontrar un conjunto de valores para los parámetros de todas las capas en una red, de modo que la red mapee correctamente muestras de entrada a sus etiquetas asocidas.\n",
        "\n",
        "La función de pérdida (_loss_) mide cuán lejos está la salida de lo que se espera. La función de pérdida coge las predicciones de la red y el valor verdadero de la etiqueta y calcula un error cometido en una muestra de entrada específica.\n",
        "\n",
        "El optimizador usa la medida del error cometido como señal de retroalimentación del sistema para ajustar el valor de los parámetros, en un dirección que disminuya el cálclo de error para la muestra actual. Esto se conoce como \"retropropagación\" (**Backpropagation**).\n",
        "\n",
        "Entrenar una red neuronal es aprender los valores de los parámetros (_weight_ $w$ y _bias_ $b$) es un proceso iterativo de \"ir y venir\" por las capas de las neuronas. A la acción de \"ir\" propagando hacia adelante se le llama _forward propagation_ y a la de \"venir\" se le llama _back propagation_.\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1200/1*rLUL1hmN8E53lqGuei-jyw.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ootSXoa36Z9S"
      },
      "source": [
        "Idealmente se quiere que el error calculado sea cero, es decir, que la divergencia entre lo estimado y lo esperado sea cero. Eso se consigue a medida que el modelo entrenado ajusta los pesos de las interconexiones de las neuronas.\n",
        "\n",
        "Para reducir el error cada vez que la red haga una predicción se usa una técnica llamda descenso del gradiente (_Gradiente Descent_). Esta técnica va cambiando los pesos en pequeños incrementos con la ayuda del cálculo de la derivada de la función de pérdida, lo cual nos permite ver en qué dirección descender hacia el mínimo global.\n",
        "\n",
        "El _Gradient Descent_ usa la primera derivada de la función de pérdida cuando realiza la actualización en los parámetros. El proceso consise en encadenar la derivada de la funciń de pérdida con las derivadas de cada capa de la red neuronal.\n",
        "\n",
        "El gradiente, siempre apunta hacia el sentido en el que se incrementa el valor de la función de pérdida. Por tanto, si se usa el negativo del gradiente podemos conseguir el sentido en que tendemos a reducir la función de pérdida.\n",
        "\n",
        "Para determinar el siguiente valor del parámetro, el algoritmo de descenso del gradiente modiica el valro inicial del parámetro para ir en sentido contrario al del gradiente, añadiendo así una cantidad proporcional a este. La magnitud de este cambio está determinada por el valor del gradiente y por un hiperparámetro rango de aprendizaje (_leraning rate_) y que nos determina el tamaño del avance.\n",
        "\n",
        "El término estocástico se refiere al hecho de que cada dato se extrae al azar (es un sinónimo científico de aleatorio).\n",
        "\n",
        "En inglés a los lotes refiere por _batches_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofjzqiMB6Rab"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train,y_train, epochs=5, batch_size=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T61-CGhBD-_2"
      },
      "source": [
        "Se esta diviendo los datos en lotes de tamaño 100 con el argumento de *batch_size* y con el argumento _epochs_ estamos inficado cuántas veces realizamos este proceso sobre todos los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRTqTxDjI4wH"
      },
      "source": [
        "**Función de Pérdida**\n",
        "\n",
        "Una función de pérdida (_loss function_) es necesario para guiar el proceso de entrenamiento de la red, y para cuantificiar lo cercana que está una determinada red neuronal de su ideal mientras está en el proceso de entrenamiento.\n",
        "\n",
        "A veces se usa también sinónimos como función de coste (_cost function_), función de error (_error function_) o función objetivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCy3XfXd6RYU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "my_optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "model.compil(optimizer=my_optimizer,\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxGmzT2JtlmW"
      },
      "source": [
        "Acabamos de crear nuestro propio optimizador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmnYNR70MPvE"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "cxc2SP0vyeY1",
        "yMCV_5BLyjMK",
        "A6LAsU_j-wOY",
        "TV798ygOtr8g"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}